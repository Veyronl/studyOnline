### 视觉和语言预训练（Vision-and-Language Pre-training，VLP）
目标函数也基本上是 image text matching（图像-文本的匹配的loss）和 masked language modeling（NLP中如BERT等使用的掩码学习)

### 从模型架构上来分
#### 单流架构 基于Self-Attention
- 特点：
  - 多个模态的内容直接拼接，输入到模型中。相当于将单模态的内部交互与多模态之间的交互合在一起
  例如：vision的q来自于图像，其k、v则即来自于图像也来自于文本；文本侧也是如此。
#### 双流架构 基于Cross-Attention
- 特点：
  - 先做单模态内部交互，再做多模态之间的交互。
  - 交叉注意力层：查询Query来自一种模式，而key、value来自另一种模式。通常包含两个单向交叉注意力层：一个是语言到视觉，另一个是视觉到与语言。他们负责在两种模式之间交换信息和调整语义。
#### Dual Encoder
- 特点
  - 经典范式：CLIP
  - 浅层交互：模态之间仅使用相似度的交互
  - 需要在一个预训练好的
  - 优点：文本和图像侧的表示是预训练好的，文本encoder与图像encoder完全解耦
  - 缺点：只用了浅层交互，无法适用于多模态推理方面的工作
  
#### Fusion Encoder + Dual encoder
  - 经典范式：VLMO 
    - 提出了混合模态专家Transformer（Mixture-of-Modality-Experts Tranformer）
    - VLMO还提出了新的分阶段的预训练策略，后面细讲
  - 出发点：fusion encoder的交互更深入，能学习到更细粒度的跨模态信息特征，但是计算复杂度高，而dual encoder交互不够，但推理速度更快。希望将两种encoder方式融合，让模型学习到细粒度多模态信息的同时也可以学到更宏观的多模态表示。
    - 三类输入：
      - 图像侧：Image Patch
      - 文本侧：复用Bert的文本编码方式
      - 图-文输入：由图像输入和文本嵌入拼接而成
    - 目标：训练三个不同的专家：分别是视觉专家（V-FFN）、语言专家（L-FFN）、视觉-语言专家(VL-FFN)，让他们完成各自的预训练任务。
  - 优点
    - 更好的适配不同的下游任务，可以完成视觉-语言的检索、分类（视觉问答、视觉推理）等任务  
### 从发展历程来说
#### ViT
《AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》，翻译而来就是，一张图片值256（16 X 16）个词。  
参考链接https://zhuanlan.zhihu.com/p/617175563?utm_id=0
1.将图像等分成个图像块（image patch），这里的就是（为了简化，作者在上图用了）；  
2.将图像块从左到右，从上到下依次输入到线性映射层（全连接层），输入之前对每个图像块进行铺平，全连接层将每个图像块映射成维向量（embeddings）；  
3.设置一个类别记号（class token），其类型为可学习的张量，维度为D维（图中的*）；  
4.为“类别记号+每个图像块特征“赋予一个位置编码，位置编码是一个可学习的参数，维度为D；  
5.将“类别记号+每个图像块特征“与其位置编码进行按位相加，作为Transformer编码器的输入；  
6.取Transformer编码器输出的第一个embedding（即类别记号对应的embedding），将其输入到多层感知器中（MLP），输出所属类别概率；  
补充描述：   
如果输入图像的分辨率较高，那么仍保持每个图像块的尺度大小不变，这样的话，图像块的数量会增加，输入到ViT的序列长度也会增加；  
类别分类是借鉴BERT的。ViT是用于图像分类任务的，图分类是CNN提取特征后+全连接层将提取的图像特征输出类别概率。这里最终的图像特征，可以用池化操作（pooling）对Transformer输出的所有序列进行均值池化获得的，也可以取输出序列的第一个embedding。这里作者选择了后者；  
ViT仅采用基础Transformer中的编码器用于图像特征提取，因为是分类任务不是生成任务（类似翻译），所以无需解码器；  
ViT中的Transformer编码器由多层编码层构成，每个编码层主要由一个多头注意力和多层感知器MLP（全连接层+激活）通过残差连接构成；  
#### ViLT
Vision-and-Language Transformer Without Convolution or Region Supervision  

